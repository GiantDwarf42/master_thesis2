{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the source of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "def main(task_id):\n",
    "\n",
    "    print(\"main is running\")\n",
    "\n",
    "    print(f\"job ID exists: {task_id}\")\n",
    "    #%%\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    #self written modules\n",
    "    import MMD\n",
    "\n",
    "    #%%\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #%%\n",
    "    # this is necessary to not just get the same values 150 times\n",
    "    seed = int(task_id)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #%%\n",
    "    folder_name= \"Logistic_output\"\n",
    "    lr = 0.1\n",
    "\n",
    "\n",
    "    #######################################################################################################################3\n",
    "    # setup parameter permutations\n",
    "\n",
    "    # #sample sizes\n",
    "    x_sample_sizes = [50,100,200,500,1000]\n",
    "    y_sample_sizes = [50,100,200,500,1000]\n",
    "\n",
    "    # true parameters\n",
    "    alpha_list = [0.05, 0.1, 0.3, 0.7, 0.95]\n",
    "\n",
    "    #dims\n",
    "    dim_list = [1,2,5,10,20]\n",
    "\n",
    "    # bandwidth\n",
    "    b_list = [\"AUTO\", 0.01, 0.1]\n",
    "\n",
    "    # number number iterations\n",
    "    nr_iterations = 800\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #going through parameter permutation\n",
    "\n",
    "    for b_value in b_list:\n",
    "\n",
    "        for alpha in alpha_list:\n",
    "\n",
    "            for dim in dim_list:\n",
    "\n",
    "                for x_sample_size in x_sample_sizes:\n",
    "\n",
    "                    for y_sample_size in y_sample_sizes:\n",
    "                        \n",
    "                        if x_sample_size >= y_sample_size:\n",
    "                        \n",
    "                            \n",
    "                            if b_value == \"AUTO\":\n",
    "                                \n",
    "                                file_name = f\"alpha{alpha}_dim{dim}_bAUTO_xsize{x_sample_size}_ysize{y_sample_size}_ID{task_id}\"\n",
    "                            \n",
    "\n",
    "                            elif isinstance(b_value, float):\n",
    "                                \n",
    "                                file_name = f\"alpha{alpha}_dim{dim}_b{b_value}_xsize{x_sample_size}_ysize{y_sample_size}_ID{task_id}\"\n",
    "\n",
    "\n",
    "                            \n",
    "\n",
    "                            y = MMD.sample_multivariate_logistic(y_sample_size,dim,alpha,device)\n",
    "\n",
    "                            # check if b heuristic needs to be calculated\n",
    "                            if b_value == \"AUTO\":\n",
    "\n",
    "                                # starting point for bandwidth \n",
    "                                b_params = {\"alpha\": 0.5}\n",
    "\n",
    "                                # b heuristic could also just be a value\n",
    "                                b = MMD.calc_b_heuristic(y, x_sample_size, \"logistic\", device, b_params).item()\n",
    "\n",
    "                            else:\n",
    "                                b = b_value\n",
    "\n",
    "                            #check if b needs to be iteratively updated\n",
    "                            if b_value == \"AUTO\":\n",
    "                                b_update = 100\n",
    "                            else:\n",
    "                                b_update = False\n",
    "                            \n",
    "                            \n",
    "\n",
    "                            #take start time\n",
    "                            now=datetime.now()\n",
    "\n",
    "                            #setup the parameters to optimize\n",
    "                            alpha_hat = torch.tensor([0.5]).to(device).requires_grad_()\n",
    "                            \n",
    "                            # setup optimizer\n",
    "                            optimizer = torch.optim.Adam([alpha_hat], lr=lr)\n",
    "\n",
    "                            \n",
    "                            # run the actual simulation\n",
    "                            simulated_df = MMD.training_loop_multi_logist(alpha_hat, y, nr_iterations, x_sample_size, device, b, optimizer, epoch_print_size=False,b_update=b_update)\n",
    "\n",
    "                            \n",
    "\n",
    "                            simulated_df.to_csv(f\"{folder_name}/{file_name}.csv\")\n",
    "                        \n",
    "                        else:\n",
    "                            continue\n",
    "                        \n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python my_calculation.py <task_id>\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    task_id = sys.argv[1]\n",
    "    main(task_id)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 76 (1152807292.py, line 79)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 79\u001b[1;36m\u001b[0m\n\u001b[1;33m    b_params = {\"alpha\": 0.5}\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'if' statement on line 76\n"
     ]
    }
   ],
   "source": [
    "print(\"main is running\")\n",
    "\n",
    "print(f\"job ID exists: {task_id}\")\n",
    "#%%\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "#self written modules\n",
    "import MMD\n",
    "\n",
    "#%%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "# this is necessary to not just get the same values 150 times\n",
    "seed = int(task_id)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#%%\n",
    "folder_name= \"Logistic_output\"\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "#######################################################################################################################3\n",
    "# setup parameter permutations\n",
    "\n",
    "# #sample sizes\n",
    "x_sample_sizes = [50,100,200,500,1000]\n",
    "y_sample_sizes = [50,100,200,500,1000]\n",
    "\n",
    "# true parameters\n",
    "alpha_list = [0.05, 0.1, 0.3, 0.7, 0.95]\n",
    "\n",
    "#dims\n",
    "dim_list = [1,2,5,10,20]\n",
    "\n",
    "# bandwidth\n",
    "b_list = [\"AUTO\", 0.01, 0.1]\n",
    "\n",
    "# number number iterations\n",
    "nr_iterations = 800\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#going through parameter permutation\n",
    "\n",
    "for b_value in b_list:\n",
    "\n",
    "\tfor alpha in alpha_list:\n",
    "\n",
    "\t\tfor dim in dim_list:\n",
    "\n",
    "\t\t\tfor x_sample_size in x_sample_sizes:\n",
    "\n",
    "\t\t\t\tfor y_sample_size in y_sample_sizes:\n",
    "\t\t\n",
    "\t\t\t\t\tif x_sample_size >= y_sample_size:\n",
    "\t\t\n",
    "\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "\t\t\t\t\t\ty = MMD.sample_multivariate_logistic(y_sample_size,dim,alpha,device)\n",
    "\n",
    "\t\t\t\t\t\t# check if b heuristic needs to be calculated\n",
    "\t\t\t\t\t\tif b_value == \"AUTO\":\n",
    "\n",
    "\t\t\t\t\t\t# starting point for bandwidth \n",
    "\t\t\t\t\t\tb_params = {\"alpha\": 0.5}\n",
    "\n",
    "\t\t\t\t\t\t# b heuristic could also just be a value\n",
    "\t\t\t\t\t\tb = MMD.calc_b_heuristic(y, x_sample_size, \"logistic\", device, b_params).item()\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tb = b_value\n",
    "\n",
    "\t\t\t\t\t#check if b needs to be iteratively updated\n",
    "\t\t\t\t\tif b_value == \"AUTO\":\n",
    "\t\t\t\t\t\tb_update = 100\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tb_update = False\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\n",
    "\t\t\t\t\t#take start time\n",
    "\t\t\t\t\tnow=datetime.now()\n",
    "\n",
    "\t\t\t\t\t#setup the parameters to optimize\n",
    "\t\t\t\t\talpha_hat = torch.tensor([0.5]).to(device).requires_grad_()\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# setup optimizer\n",
    "\t\t\t\t\toptimizer = torch.optim.Adam([alpha_hat], lr=lr)\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# run the actual simulation\n",
    "\t\t\t\t\tsimulated_df = MMD.training_loop_multi_logist(alpha_hat, y, nr_iterations, x_sample_size, device, b, optimizer, epoch_print_size=False,b_update=b_update)\n",
    "\n",
    "\t\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "#self written modules\n",
    "import MMD\n",
    "\n",
    "#%%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "# this is necessary to not just get the same values 150 times\n",
    "seed = int(42)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing know broken case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample_size = 50\n",
    "x_sample_size = 50\n",
    "dim = 2\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(y).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_realizations_list = []\n",
    "\n",
    "for i in np.arange(1000):\n",
    "\ty = MMD.sample_multivariate_logistic(y_sample_size,dim,alpha,device)\n",
    "\n",
    "\ty_realizations_list.append(torch.isnan(y).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False),\n",
       " tensor(False)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_realizations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_params = {\"alpha\": 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = MMD.calc_b_heuristic(y, x_sample_size, \"logistic\", device, b_params).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42038932073571383"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "\n",
    "\n",
    "#######################################################################################################################3\n",
    "# setup parameter permutations\n",
    "\n",
    "# #sample sizes\n",
    "x_sample_sizes = [50]\n",
    "y_sample_sizes = [50]\n",
    "\n",
    "# true parameters\n",
    "alpha_list = [0.05]\n",
    "\n",
    "#dims\n",
    "dim_list = [2]\n",
    "\n",
    "# bandwidth\n",
    "b_list = [0.01]\n",
    "\n",
    "# number number iterations\n",
    "nr_iterations = 800\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#going through parameter permutation\n",
    "\n",
    "for b_value in b_list:\n",
    "\n",
    "\tfor alpha in alpha_list:\n",
    "\n",
    "\t\tfor dim in dim_list:\n",
    "\n",
    "\t\t\tfor x_sample_size in x_sample_sizes:\n",
    "\n",
    "\t\t\t\tfor y_sample_size in y_sample_sizes:\n",
    "\t\t\n",
    "\t\t\t\t\tif x_sample_size >= y_sample_size:\n",
    "\t\t\n",
    "\t\t\t\n",
    "\t\t\t\t\t\n",
    "\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "\t\t\t\t\t\ty = MMD.sample_multivariate_logistic(y_sample_size,dim,alpha,device)\n",
    "\n",
    "\t\t\t\t\t\t# check if b heuristic needs to be calculated\n",
    "\t\t\t\t\t\tif b_value == \"AUTO\":\n",
    "\n",
    "\t\t\t\t\t\t\t# starting point for bandwidth \n",
    "\t\t\t\t\t\t\tb_params = {\"alpha\": 0.5}\n",
    "\n",
    "\t\t\t\t\t\t\t# b heuristic could also just be a value\n",
    "\t\t\t\t\t\t\tb = MMD.calc_b_heuristic(y, x_sample_size, \"logistic\", device, b_params).item()\n",
    "\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tb = b_value\n",
    "\n",
    "\t\t\t\t\t\t#check if b needs to be iteratively updated\n",
    "\t\t\t\t\t\tif b_value == \"AUTO\":\n",
    "\t\t\t\t\t\t\tb_update = 100\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tb_update = False\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\n",
    "\t\t\t\t\t\t#take start time\n",
    "\t\t\t\t\t\tnow=datetime.now()\n",
    "\n",
    "\t\t\t\t\t\t#setup the parameters to optimize\n",
    "\t\t\t\t\t\talpha_hat = torch.tensor([0.5]).to(device).requires_grad_()\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# setup optimizer\n",
    "\t\t\t\t\t\toptimizer = torch.optim.Adam([alpha_hat], lr=lr)\n",
    "\n",
    "\t\t\t\n",
    "\t\t\t\t\t\t# run the actual simulation\n",
    "\t\t\t\t\t\tsimulated_df = MMD.training_loop_multi_logist(alpha_hat, y, nr_iterations, x_sample_size, device, b, optimizer, epoch_print_size=False,b_update=b_update)\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_hat</th>\n",
       "      <th>MMD</th>\n",
       "      <th>b</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.003034</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.010974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.546596</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.014962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.498854</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.018954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430069</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.023938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.364377</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.028925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>45.699729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>45.703685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>45.707672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>45.711662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>45.715652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha_hat       MMD     b       time\n",
       "0     0.600000 -0.003034  0.01   0.010974\n",
       "1     0.546596 -0.001700  0.01   0.014962\n",
       "2     0.498854 -0.000478  0.01   0.018954\n",
       "3     0.430069 -0.003326  0.01   0.023938\n",
       "4     0.364377 -0.002688  0.01   0.028925\n",
       "..         ...       ...   ...        ...\n",
       "795        NaN       NaN  0.01  45.699729\n",
       "796        NaN       NaN  0.01  45.703685\n",
       "797        NaN       NaN  0.01  45.707672\n",
       "798        NaN       NaN  0.01  45.711662\n",
       "799        NaN       NaN  0.01  45.715652\n",
       "\n",
       "[800 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
